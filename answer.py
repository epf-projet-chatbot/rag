from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import os
from dotenv import load_dotenv
load_dotenv()

llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.2, google_api_key=os.getenv("GOOGLE_API_KEY"))

embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

# Chemin de la base de donn√©es Chroma adapt√© pour Docker et d√©veloppement local
chroma_db_path = os.path.join(os.path.dirname(__file__), "chroma_db")
print(f"üîç Chemin de la base Chroma : {chroma_db_path}")
print(f"üîç Existence du r√©pertoire : {os.path.exists(chroma_db_path)}")

vector_store = Chroma(persist_directory=chroma_db_path, embedding_function=embeddings)
retriever = vector_store.as_retriever(search_kwargs={"k": 5})

custom_prompt = PromptTemplate.from_template("""
Tu es un assistant juridique sp√©cialis√© dans le cadre l√©gal des Junior Entreprises fran√ßaises. Utilise les informations suivantes pour r√©pondre √† la question de mani√®re factuelle et concise.

Contexte :
{context}

Question :
{question}

R√©ponse :
""")

rag_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True,
    chain_type_kwargs={"prompt": custom_prompt}
)

""" query = input("Posez votre question juridique sur les Junior Entreprises : ")
result = rag_chain.invoke({"query": query})

print("R√©ponse :", result["result"])
for doc in result["source_documents"]:
    print(f"Source: {doc.metadata.get('source')}, page: {doc.metadata.get('page')}") """

def generate_answer(query):
    result = rag_chain.invoke({"query": query})
    answer = result["result"]
    sources = [(doc.metadata.get('source'), doc.metadata.get('page')) for doc in result["source_documents"]]
    return answer, sources